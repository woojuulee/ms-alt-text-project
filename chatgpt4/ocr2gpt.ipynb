{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install azure-ai-vision\n",
    "!python -m pip install --upgrade azure-ai-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-vision\n",
    "!pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.ai.vision as sdk\n",
    "import json\n",
    "\n",
    "service_options = sdk.VisionServiceOptions(os.environ[\"VISION_ENDPOINT\"],\n",
    "                                           os.environ[\"VISION_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.ai.vision.VisionServiceOptions object at 0x000001C23CC28D60>\n"
     ]
    }
   ],
   "source": [
    "print(service_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 파일 입력 시, gpt3.5 사용한 최종 대체텍스트 결과 출력하는 코드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dense Captions:\n",
      "   'a snow covered tree and cars', Rectangle(x=0, y=0, w=1054, h=535), Confidence: 0.7152\n",
      "   'a white car parked in a parking lot', Rectangle(x=0, y=267, w=350, h=166), Confidence: 0.8197\n",
      "   'a white car parked in a parking lot', Rectangle(x=176, y=249, w=260, h=130), Confidence: 0.7094\n",
      "   'a snow covered tree branch', Rectangle(x=409, y=285, w=424, h=239), Confidence: 0.6705\n",
      "   'a snow on a tree', Rectangle(x=710, y=244, w=253, h=98), Confidence: 0.6877\n",
      " Text:\n",
      "   Line: 'YONHAP NEWS', Bounding polygon {786, 464, 1045, 463, 1045, 495, 786, 496}\n",
      "{\n",
      "  \"id\": \"chatcmpl-8UmNpULosh3ywbYn85XznG9GuN9rQ\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"이 이미지들은 겨울 풍경을 포착한 것으로 보입니다. 눈으로 덮인 나무와 나뭇가지들이 얼음의 무게로 굽어 있는 모습이 인상적이고, 고요하고 차가운 분위기를 자아내고 있습니다. 또한, 흰색 차량이 주차장에 덮힌 새하얀 눈과 대조를 이뤄 서 있습니다. 사진 속에는 'YONHAP NEWS'라는 텍스트도 확인되는데, 이는 이미지에 포함된 텍스트 정보입니다.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1702346517,\n",
      "  \"model\": \"gpt-4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_50a4261de5\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 171,\n",
      "    \"prompt_tokens\": 475,\n",
      "    \"total_tokens\": 646\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "이 이미지들은 겨울 풍경을 포착한 것으로 보입니다. 눈으로 덮인 나무와 나뭇가지들이 얼음의 무게로 굽어 있는 모습이 인상적이고, 고요하고 차가운 분위기를 자아내고 있습니다. 또한, 흰색 차량이 주차장에 덮힌 새하얀 눈과 대조를 이뤄 서 있습니다. 사진 속에는 'YONHAP NEWS'라는 텍스트도 확인되는데, 이는 이미지에 포함된 텍스트 정보입니다.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def print_alt_text(subject) :\n",
    "\n",
    "    # 1. 이미지 불러오기 \n",
    "    image_path = 'image/{0}.jpg'.format(subject)\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_buffer = f.read()\n",
    "\n",
    "    # 2. Azure Image analysis(captioning) API 사용하기\n",
    "    image_source_buffer = sdk.ImageSourceBuffer()\n",
    "    image_source_buffer.image_writer.write(image_buffer)\n",
    "    vision_source = sdk.VisionSource(image_source_buffer=image_source_buffer)\n",
    "\n",
    "    analysis_options = sdk.ImageAnalysisOptions()\n",
    "    analysis_options.features = (\n",
    "        sdk.ImageAnalysisFeature.DENSE_CAPTIONS |\n",
    "        sdk.ImageAnalysisFeature.TEXT\n",
    "    )\n",
    "\n",
    "    analysis_options.language = \"en\"\n",
    "    analysis_options.gender_neutral_caption = True\n",
    "\n",
    "    # API 호출\n",
    "    image_analyzer = sdk.ImageAnalyzer(service_options, vision_source, analysis_options) \n",
    "    result = image_analyzer.analyze()\n",
    "    if result.reason == sdk.ImageAnalysisResultReason.ANALYZED:\n",
    "        if result.dense_captions is not None: # Image Caption 결과\n",
    "            print(\" Dense Captions:\")\n",
    "            caption_li = []\n",
    "            for caption in result.dense_captions:\n",
    "                print(\"   '{}', {}, Confidence: {:.4f}\".format(caption.content, caption.bounding_box, caption.confidence))\n",
    "                caption_li.append(caption.content)\n",
    "\n",
    "        if result.text is not None: # Image OCR 결과\n",
    "            print(\" Text:\")\n",
    "            text_li = []\n",
    "            for line in result.text.lines:\n",
    "                points_string = \"{\" + \", \".join([str(int(point)) for point in line.bounding_polygon]) + \"}\"\n",
    "                print(\"   Line: '{}', Bounding polygon {}\".format(line.content, points_string))\n",
    "                text_li.append(line.content)\n",
    "                # for word in line.words:\n",
    "                #     points_string = \"{\" + \", \".join([str(int(point)) for point in word.bounding_polygon]) + \"}\"\n",
    "                #     # print(\"     Word: '{}', Bounding polygon {}, Confidence {:.4f}\"\n",
    "                #     #       .format(word.content, points_string, word.confidence))\n",
    "\n",
    "    else:\n",
    "        error_details = sdk.ImageAnalysisErrorDetails.from_result(result)\n",
    "        print(\" Analysis failed.\")\n",
    "        print(\"   Error reason: {}\".format(error_details.reason))\n",
    "        print(\"   Error code: {}\".format(error_details.error_code))\n",
    "        print(\"   Error message: {}\".format(error_details.message))\n",
    "\n",
    "    text_ext =  ' '.join(text_li)\n",
    "    dic = {'caption' : caption_li, 'ocr' : text_ext }\n",
    "\n",
    "    # 3. Image 캡션과 OCR결과 json파일로 저장하기\n",
    "    with open('fromocr/{0}.json'.format(subject), 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(dic, ensure_ascii=False, indent=4))\n",
    "\n",
    "    # 4. OCR 결과 불러오기\n",
    "    json_file_path = r\"fromocr\\{0}.json\".format(subject)\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 5. AzureOpenAI API 호출하기\n",
    "    client = AzureOpenAI(\n",
    "        # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
    "        api_version=\"2023-07-01-preview\",\n",
    "        # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
    "        azure_endpoint=\"\",\n",
    "        api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-instant\",  # e.g. gpt-35-instant \n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": str(data) + \n",
    "                \"\"\" 위 딕셔너리의 caption의 value값은 이미지의 그림을 설명하는 것이고, ocr의 value값은 OCR된 이미지에 나와있는 모든 텍스트야.\n",
    "                너는 이 둘을 전체적으로 종합해서 존댓말로 시각장애인한테 설명해야하는 상황이야. \n",
    "                단,OCR의 VALUE값의 길이가 200자 이상일 경우이거나 이미지의 주요 물체가 식품일 경우, ocr value값이 caption value값보다 더 중요해. \n",
    "                그럴 경우에는, ocr value값에서 사람이 반드시 알아야하는 정보 최소 3개~5개를 말해줘. 식품의 영양정보는 반드시 정보 그대로 말해줘.\n",
    "                또는, OCR의 VALUE값의 길이가 200자 미만일 경우이거나  이미지의 주요 물체가 의류일 경우 또는 다양한 색상이 있는 경우, caption value값에 초점을 맞춰서 전체적인 모습을 색상, 질감, 모양, 형태에 대해  전체 답변을 2~3문장내로 풍부하게 묘사해줘. 또 조건이 있어. 단, 너의 말에 OCR이라는 단어는 절대 넣지말고, 네, 알겠습니다. 이런 말은 하지말아줘.\n",
    "    \"\"\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    print(completion.model_dump_json(indent=2))\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "    txt_file_path = r\"result\\{0}3.5.txt\".format(subject)\n",
    "    with open(txt_file_path, 'w') as file:\n",
    "        file.write(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "print_alt_text(\"snow\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALTER_TEXT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
